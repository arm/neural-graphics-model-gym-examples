{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPDX-FileCopyrightText: Copyright 2025 Arm Limited and/or its affiliates <open-source-office@arm.com>\\\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization Aware Training Example\n",
    "---\n",
    "This notebook shows how to use the Neural Graphics Model Gym to run quantization aware training of the Neural Super Sampling model, as well as how to export to VGF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "**Before running the notebook:**\n",
    "\n",
    "Check the environment prerequisites and follow the set up instructions in the [README.md](../../README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ng_model_gym package.\n",
    "import ng_model_gym as ngmg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Set training/evaluation configuration parameters using a .json file.\n",
    "# Let's use the default configuration file provided in the package.\n",
    "cfg_path = Path(\"../../assets/nss/tutorial_config.json\")\n",
    "\n",
    "# Load config object from the .json file\n",
    "config = ngmg.load_config_file(cfg_path)\n",
    "\n",
    "# Enable minimal logging for ng_model_gym.\n",
    "# For more detailed logs set log_level to logging.INFO or logging.DEBUG.\n",
    "ngmg.logging_config(config, log_level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print as rprint\n",
    "\n",
    "# Let's inspect the loaded config object.\n",
    "rprint(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on each of the parameters in the config object, run the following command and note their *description* fields, expected type etc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngmg.print_config_options()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The config object is mutable, so the default parameters may be overwritten as desired:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set specific train dataset\n",
    "# Note: such a small dataset is only suitable for ease of demonstration, and will not achieve high quality\n",
    "config.dataset.path.train = Path(\"../../data/nss/datasets/train\")\n",
    "\n",
    "# Overrides to allow for a smaller dataset and shorter training run\n",
    "config.dataset.recurrent_samples = 4\n",
    "config.train.batch_size = 4\n",
    "config.train.qat.number_of_epochs = 2\n",
    "\n",
    "# Enable fine-tuning from an existing model file\n",
    "config.train.finetune = True\n",
    "\n",
    "# Path to previously trained .pt model file. For this demo, we will use the provided pretrained .pt file\n",
    "config.train.pretrained_weights = \"../../data/nss/weights/nss_v0.1.0_fp32.pt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** depending on your machine, you may need to reduce the train batch size when running QAT training compared to fp32 training. ExecuTorch requires additional GPU overhead which could result in OOM errors if the training dataset configuration approaches your GPU capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Quantization Aware Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call the do_training function to quantize aware train the model for 2 epochs on 4 reccurrent frames, as per our defined config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ng_model_gym import TrainEvalMode\n",
    "\n",
    "# We pass in the modified config object, and set the training mode to perform QAT fine-tuning on the pretrained weights.\n",
    "qat_ckpt_path = ngmg.do_training(config, training_mode=TrainEvalMode.QAT_INT8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export to VGF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now export our model using Executorch to a VGF file ready to be used in your game engine of choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ng_model_gym import ExportType\n",
    "\n",
    "ngmg.do_export(config, qat_ckpt_path, export_type=ExportType.QAT_INT8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exported VGF file should now be visible in the `tutorials/nss/output/vgf` directory, by default."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
